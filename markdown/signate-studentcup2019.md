# SIGNATE: Student Cup 2019

## メンバー

- [Hiroshi Yoshihara](https://github.com/analokmaus)\*
- [Taiki Yamaguchi](https://github.com/yamaguchitai)
- [Kosaku Ohno](https://github.com/Kevinrobot34)
- [Masato Tsutsumi](https://github.com/masa10223)

\*この記事を書いた熊

## 結果

Public:   10817.55866 (**1位**)

Private:  11713.39842 (**1位**)

- [ソースコード](https://github.com/analokmaus/signate-studentcup2019)
- [解説スライド](https://www.slideshare.net/ssuserf0844f/zozei)

## 概要

**[コンペ公式ページ](https://signate.jp/competitions/182)**

- 物件の基礎情報から賃貸価格を予測する
- データは文字列のCSVで与えられる
- 評価指標はなんと**RMSE**(後述)
- 外部データ使用可

## ポイント
- 賃貸∝面積
- 同じ建物の同定・表記揺れの修正
- 評価指標RMSEの最小化のために予測値が高い物のズレを最小化するためのstackingの考案

## 弊チームの記録

### 参加から初提出まで

Kaggleの[細胞コンペ](./kaggle-recursion.md)が終わったばかりで完全に冬眠モードのときに、
大学の友人から「SIGNATEで学生限定のコンペがある、出ないか？」と誘われた。

熊「嫌だ。来年までもうコンペはやらん。」

友「不動産の家賃を予測するのがテーマなんだけど、、」

熊「やるぞ。サーモンを持って来い。代金は賞金から払う。」

実は前の年に某社で不動産価格の査定をAIで自動化するプロジェクトをやったことがある熊はこの時点で勝利を確信し、
満を辞して参加を決めた。

ドメイン知識としてこの業界では「不動産価格査定マニュアル」というものがあり、
そこでは**類似した比較物件をベースに比較物件の単位面積価格に物件スコア比と面積をかけて
算出され、その物件スコアは築年数・最寄り駅からの徒歩分・所在階などが大きく関与している**(マンションの場合)ということをすでに知っていた。

不動産価格と賃貸価格の間に強い相関があるのは言わずもがな、つまり**単価面積あたりの賃料**をターゲットにして回帰すれば良いことはコンペを始める段階でわかっていた。

その日のうちに最低限のデータのクレンジングを行い、住所・アクセス・設備などの文字列を取り扱えるカテゴリカル変数に変換した。正直この辺りの文字列はかなり綺麗に構造化されており、処理は簡単であった。

経験上こういったカテゴリカル多めなデータはYandexの[CatBoost](https://github.com/catboost/catboost)が強いと想定されたので、最初の提出は**単価面積あたりの賃料**をターゲットにクレンジングしたデータをそのまま`CatBoostRegressor`に流し込んだ。CatBoostはその設計上カテゴリカル変数のエンコーディングを行う必要がないのも嬉しい。
その結果はpublic LB 14982で当時3位だった。

勝てそうだ。


### 暫定1位を取るまで

次に、**同じだと思われる建物** がtrain/testデータの双方にかなり多く含まれていることに気がついたので、
このことを利用することを考えた。具体的には以下のことを行った。
- 住所(町丁まで)+建物構造+築年数+階層で建物idを振った
- 面積と所在階が同じ物件はtrainから穴埋めを行った
  - そうでない物件は面積と所在階で線形回帰を行った (internal regression)
    - 決定係数が低い物は平均単位価格に面積をかけて算出した

この段階でpublic LB 13214、3回目の提出で1位になった。

勝った。

### public LB 12000台まで

次の段階としてドメイン知識から以下の温かみのある人力特徴量を追加した。
- 所在地の座標情報(所在地の連続的なエンコーディングとして)
- 最寄り駅の乗降者数などの固有情報
- 最寄り駅を使った三点測位(駅と距離のエンコーディングとして)
- 公示地価
- 公示地価の2年前から成長率
- 地域の人口
- 区ポテンシャル(各区の距離の逆数)

特徴量エンジニアリングと同時に間取りやアクセスの表記揺れの対応も行った。
これ以降、特徴量の変更は特に行っていない。

築年数や建物構造などの表記揺れが原因で建物idが寄せられていないデータを複数発見したので、
一定の基準にしたがって建物idの名寄せも行った。
また、同じ建物内でも建物に固有な項目(e.g. 所在地)が一致していないこともあったため、
建物id内の最頻値で各物件の情報を置換した。

学習部分では、建物idで **group k fold cross validation** を行い、
同一建物内のデータによって学習時にリークが発生しないように変更した。
local CVとpublic LBにある程度の相関が見られるようになった。

ここまで行い、public LB~12200まで改善した。

さらに、**internal regressionで確信度が高いtest物件を擬似ラベルとして採用** し
trainデータを42000件前後まで水増しして学習を行ったところ、public LB~12000までスコアを改善することに成功した。

この頃にlightgbmやMLPも試したが、パフォーマンスでCatBoostには敵わなかった。

### 勝利へ

ここまでで単体のモデルの精度を十分に改善できたと判断し、複数モデルの統合の検討を始めた。
まず、複数モデルの予測値を入力としてRidge回帰を行うことを考えた(simple stacking)。

このsimple stackingはpublic LBスコアを多少改善した。
その際に、異なる種類のモデルを入力に含む場合にtrainデータに過学習することを観測したため、
特徴量を変えて学習させたCatBoostモデルのみを複数入力として使用し、他のモデルを排除することにした。

さらに地域特性を考慮して、
区ごとにRidge回帰を行ったところ、スコアはpublic LB~11800まで改善した(stratified stacking)。

**もう勝った。ここで終わりにしよう。~~焼肉の時間だ。~~**

しかし、現実は甘くなかった。複数チームが驚異的な追い上げを見せてきた。
そのため、我々はさらなるスコアの改善を求められた。

そこで目をつけたのが、最初から違和感であり続けた**RMSE**という評価指標である。
通常大きく値がばらつくこの手のデータの評価指標としてはMAPEなどが一般的だが。。
すなわち、外れ値にいかに対処するかが勝敗を決するポイントであるには明確だった。

ここで、**「外れ値の外れ方は類似した外れ値物件から説明できる」** との仮定を置き、

1. 位置情報・築年数・階層などの建物に固有な変数をキーに類似した物件を集め
2. 手元にある予測値と幾つかの特徴量を足して新しい入力として使い
3. 賃貸価格を直接線形回帰で予測し元の予測値を補正する

という手法を考えた(adaptive stacking)。
様々な特徴量を試行錯誤して試していく中で、
スコアを改善する特徴量を発見することができた。

その結果、最終的にはpublic 10817 / private 11713で **勝ちました！**
